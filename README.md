# Covertype ML

Este proyecto contiene un pipeline de **Machine Learning** para el preprocesamiento, anÃ¡lisis y entrenamiento de modelos basado en **TensorFlow Data Validation (TFDV)** y **TensorFlow Transform (TFT)**.

---

## **CaracterÃ­sticas del Proyecto**

âœ… **Carga de datos** desde un archivo CSV.\
âœ… **AnÃ¡lisis exploratorio** con estadÃ­sticas y visualizaciÃ³n de datos.\
âœ… **DetecciÃ³n de anomalÃ­as** y validaciÃ³n del esquema de datos.\
âœ… **Preprocesamiento de datos** utilizando TensorFlow Transform.\
âœ… **DivisiÃ³n del dataset** en entrenamiento y prueba.\
âœ… **Almacenamiento de datos preprocesados**.

---

## **Requerimientos Previos**

Para ejecutar el proyecto, asegÃºrate de tener instaladas las siguientes dependencias:

```sh
pip install -r requirements.txt
```

---

## **Estructura del Proyecto**

```plaintext
ğŸ“‚ covertype-ml
â”‚â”€â”€ ğŸ“‚ data/                     # Directorio para almacenar el dataset
â”‚â”€â”€ ğŸ“‚ notebooks/                # Notebooks para exploraciÃ³n y anÃ¡lisis
â”‚â”€â”€ ğŸ“‚ models/                   # Carpeta para almacenar modelos entrenados
â”‚â”€â”€ ğŸ“‚ src/                      # CÃ³digo fuente del proyecto
â”‚   â”œâ”€â”€ ğŸ“œ preprocess.py         # Script para preprocesamiento de datos
â”‚   â”œâ”€â”€ ğŸ“œ train.py              # Script para entrenamiento de modelos
â”‚   â”œâ”€â”€ ğŸ“œ predict.py            # Script para realizar predicciones
â”‚   â”œâ”€â”€ ğŸ“œ utils.py              # Funciones auxiliares
â”‚â”€â”€ ğŸ“œ dataset.csv               # Dataset utilizado en el proyecto
â”‚â”€â”€ ğŸ“œ requirements.txt          # Dependencias del proyecto
â”‚â”€â”€ ğŸ“œ README.md                 # DocumentaciÃ³n del proyecto
```

---

## **Ejecutar el Proyecto**

### 1ï¸âƒ£ **Preprocesar los Datos**

Ejecuta el script de preprocesamiento para generar estadÃ­sticas, validar el esquema y transformar los datos:

```sh
python src/preprocess.py
```

Este paso genera estadÃ­sticas exploratorias y detecta anomalÃ­as en los datos.

---

### 2ï¸âƒ£ **Entrenar un Modelo**

Ejecuta el siguiente comando para entrenar un modelo sobre los datos preprocesados:

```sh
python src/train.py
```

El modelo entrenado se guardarÃ¡ en la carpeta `models/`.

---

### 3ï¸âƒ£ **Realizar Predicciones**

Ejecuta el script de predicciÃ³n con datos nuevos:

```sh
python src/predict.py --input "47.2,13.7,214.0,4925.0,1,2"
```

O puedes importar las funciones en un entorno interactivo:

```python
from src.utils import load_model, predict

model = load_model("models/trained_model.pkl")
data = [[47.2, 13.7, 214.0, 4925.0, 1, 2]]
prediction = predict(model, data)
print("PredicciÃ³n:", prediction)
```

---

## **ConclusiÃ³n**

Este pipeline permite:\
âœ… Explorar y analizar datos con **TFDV**.\
âœ… Detectar anomalÃ­as y validar esquemas.\
âœ… Aplicar transformaciones con **TFT**.\
âœ… Entrenar y evaluar modelos de clasificaciÃ³n.\
âœ… Realizar predicciones sobre nuevos datos.

